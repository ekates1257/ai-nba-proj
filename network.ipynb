{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad24407",
   "metadata": {},
   "source": [
    "ANN Final Project\n",
    "Authors: Caleb Johnson, Gabe Schwartz, Evan Kates\n",
    "Network Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09002cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calebjohnson/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# import data from csv file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, losses, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 2: Load the data\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Step 3: Define features (X) and targets (y)\n",
    "# Rookie year features\n",
    "# feature_cols = ['GP_r', 'MIN_r', 'FG_PCT_r', 'FG3M_r', 'FG3A_r', 'REB_r', 'AST_r', 'PTS_r', 'TOV_r']\n",
    "feature_cols = ['GP_r', 'MIN_r', 'FG_PCT_r', 'REB_r', 'AST_r', 'PTS_r', 'TOV_r']\n",
    "# feature_cols = ['GP_r', 'MIN_r', 'FG_PCT_r', 'GS_r', 'REB_r', 'AST_r', 'PTS_r', 'TOV_r']\n",
    "\n",
    "X = df[feature_cols]\n",
    "\n",
    "# Sophomore stats to predict\n",
    "target_cols = ['PTS_s', 'REB_s', 'AST_s']\n",
    "y = df[target_cols]\n",
    "\n",
    "# Step 4: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Feature scaling (important for neural nets)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 6: Build the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],),\n",
    "                       kernel_regularizer=regularizers.l1(0.001)),  # L1 regularization\n",
    "    keras.layers.Dense(64, activation='relu',\n",
    "                       kernel_regularizer=regularizers.l1(0.001)),\n",
    "    keras.layers.Dense(3)  # Predicting 3 values: PTS, REB, AST\n",
    "])\n",
    "\n",
    "# Define early stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',   # Watch the validation loss\n",
    "    patience=10,          # Number of epochs to wait after no improvement\n",
    "    restore_best_weights=True # After stopping, roll back to the best model\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss=losses.Huber(), metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "606e707a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.7557 - mae: 4.3996 - val_loss: 4.3542 - val_mae: 3.9953\n",
      "Epoch 2/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.9400 - mae: 3.5842 - val_loss: 3.6580 - val_mae: 3.3186\n",
      "Epoch 3/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3.2319 - mae: 2.8907 - val_loss: 3.0854 - val_mae: 2.7646\n",
      "Epoch 4/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6899 - mae: 2.3669 - val_loss: 2.6092 - val_mae: 2.3059\n",
      "Epoch 5/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.3877 - mae: 2.0872 - val_loss: 2.2959 - val_mae: 2.0064\n",
      "Epoch 6/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.1467 - mae: 1.8584 - val_loss: 2.1201 - val_mae: 1.8458\n",
      "Epoch 7/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.0786 - mae: 1.8130 - val_loss: 1.9727 - val_mae: 1.7261\n",
      "Epoch 8/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9482 - mae: 1.7064 - val_loss: 1.9072 - val_mae: 1.6840\n",
      "Epoch 9/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7851 - mae: 1.5604 - val_loss: 1.8154 - val_mae: 1.6134\n",
      "Epoch 10/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7673 - mae: 1.5638 - val_loss: 1.7522 - val_mae: 1.5666\n",
      "Epoch 11/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7484 - mae: 1.5688 - val_loss: 1.7244 - val_mae: 1.5644\n",
      "Epoch 12/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6735 - mae: 1.5137 - val_loss: 1.6800 - val_mae: 1.5379\n",
      "Epoch 13/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6282 - mae: 1.4839 - val_loss: 1.6583 - val_mae: 1.5314\n",
      "Epoch 14/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5847 - mae: 1.4497 - val_loss: 1.6275 - val_mae: 1.5093\n",
      "Epoch 15/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5349 - mae: 1.4116 - val_loss: 1.6046 - val_mae: 1.5047\n",
      "Epoch 16/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5904 - mae: 1.4882 - val_loss: 1.5768 - val_mae: 1.4899\n",
      "Epoch 17/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5110 - mae: 1.4216 - val_loss: 1.5543 - val_mae: 1.4804\n",
      "Epoch 18/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.5355 - mae: 1.4523 - val_loss: 1.5367 - val_mae: 1.4712\n",
      "Epoch 19/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4413 - mae: 1.3673 - val_loss: 1.5152 - val_mae: 1.4623\n",
      "Epoch 20/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4669 - mae: 1.4103 - val_loss: 1.5129 - val_mae: 1.4709\n",
      "Epoch 21/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4707 - mae: 1.4270 - val_loss: 1.5028 - val_mae: 1.4720\n",
      "Epoch 22/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4634 - mae: 1.4306 - val_loss: 1.4744 - val_mae: 1.4483\n",
      "Epoch 23/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4005 - mae: 1.3749 - val_loss: 1.4722 - val_mae: 1.4615\n",
      "Epoch 24/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3763 - mae: 1.3626 - val_loss: 1.4517 - val_mae: 1.4428\n",
      "Epoch 25/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4361 - mae: 1.4241 - val_loss: 1.4397 - val_mae: 1.4398\n",
      "Epoch 26/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3522 - mae: 1.3513 - val_loss: 1.4263 - val_mae: 1.4400\n",
      "Epoch 27/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3394 - mae: 1.3479 - val_loss: 1.4214 - val_mae: 1.4395\n",
      "Epoch 28/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3142 - mae: 1.3274 - val_loss: 1.4093 - val_mae: 1.4337\n",
      "Epoch 29/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3557 - mae: 1.3740 - val_loss: 1.3986 - val_mae: 1.4316\n",
      "Epoch 30/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3511 - mae: 1.3831 - val_loss: 1.3858 - val_mae: 1.4248\n",
      "Epoch 31/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3018 - mae: 1.3373 - val_loss: 1.3789 - val_mae: 1.4282\n",
      "Epoch 32/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2737 - mae: 1.3147 - val_loss: 1.3828 - val_mae: 1.4376\n",
      "Epoch 33/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3190 - mae: 1.3649 - val_loss: 1.3598 - val_mae: 1.4180\n",
      "Epoch 34/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3238 - mae: 1.3765 - val_loss: 1.3700 - val_mae: 1.4404\n",
      "Epoch 35/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3337 - mae: 1.3895 - val_loss: 1.3503 - val_mae: 1.4199\n",
      "Epoch 36/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3104 - mae: 1.3784 - val_loss: 1.3426 - val_mae: 1.4213\n",
      "Epoch 37/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3172 - mae: 1.3856 - val_loss: 1.3416 - val_mae: 1.4224\n",
      "Epoch 38/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2577 - mae: 1.3254 - val_loss: 1.3289 - val_mae: 1.4182\n",
      "Epoch 39/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2122 - mae: 1.2839 - val_loss: 1.3294 - val_mae: 1.4220\n",
      "Epoch 40/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2359 - mae: 1.3127 - val_loss: 1.3156 - val_mae: 1.4136\n",
      "Epoch 41/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3042 - mae: 1.3880 - val_loss: 1.3232 - val_mae: 1.4259\n",
      "Epoch 42/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2055 - mae: 1.2894 - val_loss: 1.3090 - val_mae: 1.4137\n",
      "Epoch 43/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2441 - mae: 1.3337 - val_loss: 1.3006 - val_mae: 1.4121\n",
      "Epoch 44/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2085 - mae: 1.3047 - val_loss: 1.3011 - val_mae: 1.4164\n",
      "Epoch 45/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2169 - mae: 1.3177 - val_loss: 1.2979 - val_mae: 1.4159\n",
      "Epoch 46/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1884 - mae: 1.2882 - val_loss: 1.2880 - val_mae: 1.4084\n",
      "Epoch 47/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2799 - mae: 1.3883 - val_loss: 1.2835 - val_mae: 1.4090\n",
      "Epoch 48/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2248 - mae: 1.3420 - val_loss: 1.2771 - val_mae: 1.4065\n",
      "Epoch 49/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2172 - mae: 1.3320 - val_loss: 1.2734 - val_mae: 1.4061\n",
      "Epoch 50/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2081 - mae: 1.3273 - val_loss: 1.2788 - val_mae: 1.4130\n",
      "Epoch 51/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2421 - mae: 1.3646 - val_loss: 1.2694 - val_mae: 1.4094\n",
      "Epoch 52/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2129 - mae: 1.3349 - val_loss: 1.2683 - val_mae: 1.4091\n",
      "Epoch 53/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.2099 - mae: 1.3310 - val_loss: 1.2570 - val_mae: 1.4020\n",
      "Epoch 54/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1687 - mae: 1.2972 - val_loss: 1.2534 - val_mae: 1.4010\n",
      "Epoch 55/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1935 - mae: 1.3254 - val_loss: 1.2589 - val_mae: 1.4120\n",
      "Epoch 56/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1765 - mae: 1.3124 - val_loss: 1.2515 - val_mae: 1.4050\n",
      "Epoch 57/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1685 - mae: 1.3109 - val_loss: 1.2521 - val_mae: 1.4084\n",
      "Epoch 58/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1600 - mae: 1.2992 - val_loss: 1.2369 - val_mae: 1.3931\n",
      "Epoch 59/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2226 - mae: 1.3670 - val_loss: 1.2466 - val_mae: 1.4098\n",
      "Epoch 60/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1736 - mae: 1.3208 - val_loss: 1.2327 - val_mae: 1.3971\n",
      "Epoch 61/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1506 - mae: 1.2976 - val_loss: 1.2391 - val_mae: 1.4056\n",
      "Epoch 62/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1446 - mae: 1.2929 - val_loss: 1.2307 - val_mae: 1.4004\n",
      "Epoch 63/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1748 - mae: 1.3234 - val_loss: 1.2297 - val_mae: 1.4000\n",
      "Epoch 64/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2120 - mae: 1.3698 - val_loss: 1.2227 - val_mae: 1.3976\n",
      "Epoch 65/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1606 - mae: 1.3263 - val_loss: 1.2233 - val_mae: 1.3992\n",
      "Epoch 66/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1865 - mae: 1.3523 - val_loss: 1.2220 - val_mae: 1.3984\n",
      "Epoch 67/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2050 - mae: 1.3657 - val_loss: 1.2175 - val_mae: 1.3996\n",
      "Epoch 68/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1646 - mae: 1.3343 - val_loss: 1.2197 - val_mae: 1.4003\n",
      "Epoch 69/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2109 - mae: 1.3784 - val_loss: 1.2123 - val_mae: 1.3974\n",
      "Epoch 70/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2527 - mae: 1.4276 - val_loss: 1.2224 - val_mae: 1.4090\n",
      "Epoch 71/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1590 - mae: 1.3304 - val_loss: 1.2069 - val_mae: 1.3946\n",
      "Epoch 72/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1321 - mae: 1.3034 - val_loss: 1.2013 - val_mae: 1.3892\n",
      "Epoch 73/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1581 - mae: 1.3359 - val_loss: 1.2116 - val_mae: 1.4024\n",
      "Epoch 74/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1478 - mae: 1.3267 - val_loss: 1.2040 - val_mae: 1.3956\n",
      "Epoch 75/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1717 - mae: 1.3525 - val_loss: 1.1988 - val_mae: 1.3925\n",
      "Epoch 76/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1907 - mae: 1.3738 - val_loss: 1.1987 - val_mae: 1.3948\n",
      "Epoch 77/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1772 - mae: 1.3609 - val_loss: 1.1962 - val_mae: 1.3934\n",
      "Epoch 78/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1766 - mae: 1.3614 - val_loss: 1.1868 - val_mae: 1.3842\n",
      "Epoch 79/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1546 - mae: 1.3386 - val_loss: 1.1931 - val_mae: 1.3927\n",
      "Epoch 80/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1324 - mae: 1.3179 - val_loss: 1.1947 - val_mae: 1.3968\n",
      "Epoch 81/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1789 - mae: 1.3681 - val_loss: 1.1888 - val_mae: 1.3899\n",
      "Epoch 82/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1674 - mae: 1.3518 - val_loss: 1.1879 - val_mae: 1.3925\n",
      "Epoch 83/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1538 - mae: 1.3470 - val_loss: 1.1818 - val_mae: 1.3882\n",
      "Epoch 84/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1425 - mae: 1.3282 - val_loss: 1.1817 - val_mae: 1.3869\n",
      "Epoch 85/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0896 - mae: 1.2746 - val_loss: 1.1879 - val_mae: 1.3970\n",
      "Epoch 86/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1606 - mae: 1.3585 - val_loss: 1.1841 - val_mae: 1.3944\n",
      "Epoch 87/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0696 - mae: 1.2627 - val_loss: 1.1718 - val_mae: 1.3823\n",
      "Epoch 88/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0719 - mae: 1.2592 - val_loss: 1.1725 - val_mae: 1.3844\n",
      "Epoch 89/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0768 - mae: 1.2761 - val_loss: 1.1754 - val_mae: 1.3892\n",
      "Epoch 90/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1202 - mae: 1.3210 - val_loss: 1.1703 - val_mae: 1.3862\n",
      "Epoch 91/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1004 - mae: 1.2959 - val_loss: 1.1731 - val_mae: 1.3882\n",
      "Epoch 92/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1683 - mae: 1.3733 - val_loss: 1.1735 - val_mae: 1.3906\n",
      "Epoch 93/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1198 - mae: 1.3154 - val_loss: 1.1739 - val_mae: 1.3935\n",
      "Epoch 94/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1041 - mae: 1.3063 - val_loss: 1.1695 - val_mae: 1.3887\n",
      "Epoch 95/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1012 - mae: 1.3021 - val_loss: 1.1613 - val_mae: 1.3795\n",
      "Epoch 96/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1557 - mae: 1.3620 - val_loss: 1.1647 - val_mae: 1.3857\n",
      "Epoch 97/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0841 - mae: 1.2919 - val_loss: 1.1620 - val_mae: 1.3845\n",
      "Epoch 98/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1302 - mae: 1.3411 - val_loss: 1.1587 - val_mae: 1.3819\n",
      "Epoch 99/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1123 - mae: 1.3210 - val_loss: 1.1603 - val_mae: 1.3858\n",
      "Epoch 100/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1272 - mae: 1.3322 - val_loss: 1.1556 - val_mae: 1.3791\n",
      "Epoch 101/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0875 - mae: 1.2918 - val_loss: 1.1600 - val_mae: 1.3866\n",
      "Epoch 102/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0193 - mae: 1.2257 - val_loss: 1.1552 - val_mae: 1.3807\n",
      "Epoch 103/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1379 - mae: 1.3484 - val_loss: 1.1500 - val_mae: 1.3788\n",
      "Epoch 104/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1311 - mae: 1.3472 - val_loss: 1.1637 - val_mae: 1.3946\n",
      "Epoch 105/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0969 - mae: 1.3047 - val_loss: 1.1495 - val_mae: 1.3785\n",
      "Epoch 106/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0961 - mae: 1.3109 - val_loss: 1.1485 - val_mae: 1.3798\n",
      "Epoch 107/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0588 - mae: 1.2729 - val_loss: 1.1573 - val_mae: 1.3914\n",
      "Epoch 108/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1216 - mae: 1.3386 - val_loss: 1.1467 - val_mae: 1.3794\n",
      "Epoch 109/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1586 - mae: 1.3786 - val_loss: 1.1521 - val_mae: 1.3877\n",
      "Epoch 110/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0614 - mae: 1.2792 - val_loss: 1.1405 - val_mae: 1.3722\n",
      "Epoch 111/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0538 - mae: 1.2666 - val_loss: 1.1498 - val_mae: 1.3876\n",
      "Epoch 112/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0914 - mae: 1.3096 - val_loss: 1.1449 - val_mae: 1.3792\n",
      "Epoch 113/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1343 - mae: 1.3533 - val_loss: 1.1439 - val_mae: 1.3815\n",
      "Epoch 114/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0878 - mae: 1.3120 - val_loss: 1.1420 - val_mae: 1.3782\n",
      "Epoch 115/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0998 - mae: 1.3211 - val_loss: 1.1482 - val_mae: 1.3885\n",
      "Epoch 116/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0831 - mae: 1.3037 - val_loss: 1.1455 - val_mae: 1.3864\n",
      "Epoch 117/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1203 - mae: 1.3494 - val_loss: 1.1359 - val_mae: 1.3762\n",
      "Epoch 118/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0707 - mae: 1.2916 - val_loss: 1.1394 - val_mae: 1.3805\n",
      "Epoch 119/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1354 - mae: 1.3639 - val_loss: 1.1380 - val_mae: 1.3796\n",
      "Epoch 120/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0644 - mae: 1.2879 - val_loss: 1.1342 - val_mae: 1.3756\n",
      "Epoch 121/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0834 - mae: 1.3108 - val_loss: 1.1359 - val_mae: 1.3800\n",
      "Epoch 122/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1325 - mae: 1.3632 - val_loss: 1.1343 - val_mae: 1.3793\n",
      "Epoch 123/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0752 - mae: 1.3007 - val_loss: 1.1255 - val_mae: 1.3698\n",
      "Epoch 124/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0845 - mae: 1.3104 - val_loss: 1.1444 - val_mae: 1.3892\n",
      "Epoch 125/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0642 - mae: 1.2921 - val_loss: 1.1222 - val_mae: 1.3636\n",
      "Epoch 126/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0282 - mae: 1.2523 - val_loss: 1.1409 - val_mae: 1.3903\n",
      "Epoch 127/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0914 - mae: 1.3187 - val_loss: 1.1305 - val_mae: 1.3800\n",
      "Epoch 128/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1031 - mae: 1.3380 - val_loss: 1.1235 - val_mae: 1.3682\n",
      "Epoch 129/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0376 - mae: 1.2651 - val_loss: 1.1266 - val_mae: 1.3755\n",
      "Epoch 130/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1121 - mae: 1.3489 - val_loss: 1.1251 - val_mae: 1.3724\n",
      "Epoch 131/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0544 - mae: 1.2912 - val_loss: 1.1198 - val_mae: 1.3687\n",
      "Epoch 132/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0322 - mae: 1.2695 - val_loss: 1.1234 - val_mae: 1.3732\n",
      "Epoch 133/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1101 - mae: 1.3526 - val_loss: 1.1303 - val_mae: 1.3841\n",
      "Epoch 134/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1035 - mae: 1.3452 - val_loss: 1.1204 - val_mae: 1.3711\n",
      "Epoch 135/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0783 - mae: 1.3097 - val_loss: 1.1206 - val_mae: 1.3725\n",
      "Epoch 136/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0196 - mae: 1.2528 - val_loss: 1.1220 - val_mae: 1.3752\n",
      "Epoch 137/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0410 - mae: 1.2768 - val_loss: 1.1228 - val_mae: 1.3764\n",
      "Epoch 138/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1252 - mae: 1.3697 - val_loss: 1.1268 - val_mae: 1.3824\n",
      "Epoch 139/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0368 - mae: 1.2820 - val_loss: 1.1121 - val_mae: 1.3647\n",
      "Epoch 140/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0134 - mae: 1.2517 - val_loss: 1.1207 - val_mae: 1.3760\n",
      "Epoch 141/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0954 - mae: 1.3375 - val_loss: 1.1152 - val_mae: 1.3695\n",
      "Epoch 142/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0583 - mae: 1.3059 - val_loss: 1.1186 - val_mae: 1.3752\n",
      "Epoch 143/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0608 - mae: 1.3007 - val_loss: 1.1112 - val_mae: 1.3660\n",
      "Epoch 144/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0368 - mae: 1.2832 - val_loss: 1.1242 - val_mae: 1.3835\n",
      "Epoch 145/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1163 - mae: 1.3570 - val_loss: 1.1117 - val_mae: 1.3686\n",
      "Epoch 146/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0566 - mae: 1.2983 - val_loss: 1.1210 - val_mae: 1.3812\n",
      "Epoch 147/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0705 - mae: 1.3105 - val_loss: 1.1148 - val_mae: 1.3755\n",
      "Epoch 148/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0131 - mae: 1.2587 - val_loss: 1.1098 - val_mae: 1.3674\n",
      "Epoch 149/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0925 - mae: 1.3411 - val_loss: 1.1111 - val_mae: 1.3707\n",
      "Epoch 150/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0887 - mae: 1.3322 - val_loss: 1.1075 - val_mae: 1.3654\n",
      "Epoch 151/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0447 - mae: 1.2877 - val_loss: 1.1092 - val_mae: 1.3699\n",
      "Epoch 152/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0873 - mae: 1.3375 - val_loss: 1.1158 - val_mae: 1.3775\n",
      "Epoch 153/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0285 - mae: 1.2717 - val_loss: 1.1076 - val_mae: 1.3691\n",
      "Epoch 154/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0707 - mae: 1.3199 - val_loss: 1.1094 - val_mae: 1.3695\n",
      "Epoch 155/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1439 - mae: 1.3950 - val_loss: 1.1096 - val_mae: 1.3744\n",
      "Epoch 156/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0267 - mae: 1.2687 - val_loss: 1.1109 - val_mae: 1.3734\n",
      "Epoch 157/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1024 - mae: 1.3520 - val_loss: 1.1107 - val_mae: 1.3748\n",
      "Epoch 158/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0873 - mae: 1.3413 - val_loss: 1.1089 - val_mae: 1.3721\n",
      "Epoch 159/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0707 - mae: 1.3186 - val_loss: 1.1138 - val_mae: 1.3810\n",
      "Epoch 160/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0412 - mae: 1.2899 - val_loss: 1.1039 - val_mae: 1.3676\n",
      "Epoch 161/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0468 - mae: 1.2946 - val_loss: 1.1121 - val_mae: 1.3778\n",
      "Epoch 162/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0700 - mae: 1.3186 - val_loss: 1.0961 - val_mae: 1.3617\n",
      "Epoch 163/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0571 - mae: 1.3094 - val_loss: 1.1180 - val_mae: 1.3869\n",
      "Epoch 164/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0798 - mae: 1.3315 - val_loss: 1.1093 - val_mae: 1.3776\n",
      "Epoch 165/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0209 - mae: 1.2733 - val_loss: 1.1066 - val_mae: 1.3727\n",
      "Epoch 166/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0971 - mae: 1.3548 - val_loss: 1.1014 - val_mae: 1.3677\n",
      "Epoch 167/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9569 - mae: 1.2026 - val_loss: 1.0972 - val_mae: 1.3645\n",
      "Epoch 168/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1439 - mae: 1.4026 - val_loss: 1.1028 - val_mae: 1.3702\n",
      "Epoch 169/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0248 - mae: 1.2836 - val_loss: 1.1054 - val_mae: 1.3750\n",
      "Epoch 170/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0262 - mae: 1.2752 - val_loss: 1.0981 - val_mae: 1.3681\n",
      "Epoch 171/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0751 - mae: 1.3364 - val_loss: 1.1113 - val_mae: 1.3797\n",
      "Epoch 172/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0382 - mae: 1.2879 - val_loss: 1.1001 - val_mae: 1.3711\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1405 - mae: 1.4103 \n",
      "Test MAE: 1.3616979122161865\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Predicted: [3.5061448 2.123413  0.7277089] | Actual: [8.60465116 8.90697674 0.23255814]\n",
      "Predicted: [4.6153526  2.4451523  0.92711157] | Actual: [4.23880597 2.11940299 0.89552239]\n",
      "Predicted: [3.5197904 2.5312018 0.7175169] | Actual: [2.67647059 1.11764706 1.82352941]\n",
      "Predicted: [8.924893  3.489143  1.5240544] | Actual: [6.84285714 3.         1.14285714]\n",
      "Predicted: [6.23248    5.280072   0.94111645] | Actual: [13.09090909 11.90909091  1.85714286]\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=300,          # Big number because early stopping will cut it off early\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test MAE: {mae}\")\n",
    "\n",
    "# Step 9: Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Show some example predictions\n",
    "for i in range(5):\n",
    "    print(f\"Predicted: {predictions[i]} | Actual: {y_test.iloc[i].values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8d722bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "We are 90% confident that the stats will be within these ranges:\n",
      "Points: ±4.60\n",
      "Rebounds: ±2.73\n",
      "Assists: ±1.27\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# 1. Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 2. Calculate residuals\n",
    "errors = y_test.values - y_pred\n",
    "\n",
    "# 3. Estimate standard deviation of residuals\n",
    "std_dev = np.std(errors, axis=0)\n",
    "\n",
    "# 4. Compute 95% confidence intervals\n",
    "# 1.96 standard deviations covers ~95% for a normal distribution\n",
    "\n",
    "conf_interval = 1.645 * std_dev\n",
    "\n",
    "print(\"We are 90% confident that the stats will be within these ranges:\")\n",
    "print(f\"Points: ±{conf_interval[0]:.2f}\")\n",
    "print(f\"Rebounds: ±{conf_interval[1]:.2f}\")\n",
    "print(f\"Assists: ±{conf_interval[2]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
