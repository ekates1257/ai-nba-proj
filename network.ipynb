{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad24407",
   "metadata": {},
   "source": [
    "ANN Final Project\n",
    "Authors: Caleb Johnson, Gabe Schwartz, Evan Kates\n",
    "Network Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09002cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calebjohnson/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/calebjohnson/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# import data from csv file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, losses, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load csv data\n",
    "df = pd.read_csv('training.csv')\n",
    "\n",
    "# define input features\n",
    "feature_cols = ['GP_r', 'MIN_r', 'FG_PCT_r', 'REB_r', 'AST_r', 'PTS_r', 'TOV_r']\n",
    "\n",
    "X = df[feature_cols]\n",
    "\n",
    "# define predicted features\n",
    "target_cols = ['PTS_s', 'REB_s', 'AST_s']\n",
    "y = df[target_cols]\n",
    "\n",
    "# create train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# create model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],),\n",
    "                       kernel_regularizer=regularizers.l1(0.001)),  # L1 regularization\n",
    "    keras.layers.Dense(64, activation='relu',\n",
    "                       kernel_regularizer=regularizers.l1(0.001)),\n",
    "    keras.layers.Dense(3)  # output layer predicts 3 stats\n",
    "])\n",
    "\n",
    "# stop early to avoid overfitting\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True # After stopping, roll back to the best model\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss=losses.Huber(), metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606e707a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4.8747 - mae: 4.5414 - val_loss: 4.4820 - val_mae: 4.1580\n",
      "Epoch 2/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0568 - mae: 3.7258 - val_loss: 3.7151 - val_mae: 3.3914\n",
      "Epoch 3/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.2618 - mae: 2.9386 - val_loss: 2.9778 - val_mae: 2.6861\n",
      "Epoch 4/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.7582 - mae: 2.4679 - val_loss: 2.3816 - val_mae: 2.1071\n",
      "Epoch 5/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.1223 - mae: 1.8393 - val_loss: 2.0982 - val_mae: 1.8386\n",
      "Epoch 6/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9473 - mae: 1.6881 - val_loss: 1.9913 - val_mae: 1.7698\n",
      "Epoch 7/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8258 - mae: 1.5992 - val_loss: 1.8997 - val_mae: 1.7033\n",
      "Epoch 8/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.8135 - mae: 1.6138 - val_loss: 1.8383 - val_mae: 1.6744\n",
      "Epoch 9/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7506 - mae: 1.5799 - val_loss: 1.7918 - val_mae: 1.6475\n",
      "Epoch 10/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5896 - mae: 1.4386 - val_loss: 1.7570 - val_mae: 1.6419\n",
      "Epoch 11/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5737 - mae: 1.4521 - val_loss: 1.7238 - val_mae: 1.6278\n",
      "Epoch 12/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5412 - mae: 1.4404 - val_loss: 1.6889 - val_mae: 1.6162\n",
      "Epoch 13/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4970 - mae: 1.4052 - val_loss: 1.6618 - val_mae: 1.6097\n",
      "Epoch 14/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4863 - mae: 1.4156 - val_loss: 1.6482 - val_mae: 1.6061\n",
      "Epoch 15/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.4117 - mae: 1.3505 - val_loss: 1.6278 - val_mae: 1.6066\n",
      "Epoch 16/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3961 - mae: 1.3564 - val_loss: 1.5927 - val_mae: 1.5888\n",
      "Epoch 17/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3668 - mae: 1.3370 - val_loss: 1.5863 - val_mae: 1.5939\n",
      "Epoch 18/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3868 - mae: 1.3739 - val_loss: 1.5675 - val_mae: 1.5842\n",
      "Epoch 19/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3212 - mae: 1.3152 - val_loss: 1.5544 - val_mae: 1.5850\n",
      "Epoch 20/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3403 - mae: 1.3540 - val_loss: 1.5557 - val_mae: 1.5931\n",
      "Epoch 21/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3292 - mae: 1.3489 - val_loss: 1.5203 - val_mae: 1.5693\n",
      "Epoch 22/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2850 - mae: 1.3116 - val_loss: 1.5299 - val_mae: 1.5913\n",
      "Epoch 23/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3554 - mae: 1.3978 - val_loss: 1.5093 - val_mae: 1.5766\n",
      "Epoch 24/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3485 - mae: 1.4029 - val_loss: 1.5037 - val_mae: 1.5796\n",
      "Epoch 25/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2950 - mae: 1.3506 - val_loss: 1.4851 - val_mae: 1.5672\n",
      "Epoch 26/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2538 - mae: 1.3114 - val_loss: 1.4915 - val_mae: 1.5823\n",
      "Epoch 27/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2900 - mae: 1.3611 - val_loss: 1.4872 - val_mae: 1.5778\n",
      "Epoch 28/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2495 - mae: 1.3206 - val_loss: 1.4551 - val_mae: 1.5563\n",
      "Epoch 29/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2220 - mae: 1.3055 - val_loss: 1.4599 - val_mae: 1.5693\n",
      "Epoch 30/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1959 - mae: 1.2894 - val_loss: 1.4406 - val_mae: 1.5509\n",
      "Epoch 31/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1997 - mae: 1.2908 - val_loss: 1.4453 - val_mae: 1.5669\n",
      "Epoch 32/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2746 - mae: 1.3841 - val_loss: 1.4463 - val_mae: 1.5665\n",
      "Epoch 33/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1833 - mae: 1.2850 - val_loss: 1.4276 - val_mae: 1.5564\n",
      "Epoch 34/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2939 - mae: 1.4130 - val_loss: 1.4319 - val_mae: 1.5655\n",
      "Epoch 35/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2025 - mae: 1.3243 - val_loss: 1.4078 - val_mae: 1.5463\n",
      "Epoch 36/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2061 - mae: 1.3319 - val_loss: 1.4235 - val_mae: 1.5680\n",
      "Epoch 37/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1741 - mae: 1.3009 - val_loss: 1.4110 - val_mae: 1.5560\n",
      "Epoch 38/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1484 - mae: 1.2766 - val_loss: 1.4053 - val_mae: 1.5566\n",
      "Epoch 39/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1949 - mae: 1.3300 - val_loss: 1.4111 - val_mae: 1.5599\n",
      "Epoch 40/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2240 - mae: 1.3608 - val_loss: 1.3968 - val_mae: 1.5537\n",
      "Epoch 41/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1895 - mae: 1.3303 - val_loss: 1.3971 - val_mae: 1.5592\n",
      "Epoch 42/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1806 - mae: 1.3227 - val_loss: 1.3840 - val_mae: 1.5509\n",
      "Epoch 43/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1731 - mae: 1.3237 - val_loss: 1.3838 - val_mae: 1.5547\n",
      "Epoch 44/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1116 - mae: 1.2653 - val_loss: 1.3696 - val_mae: 1.5407\n",
      "Epoch 45/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1411 - mae: 1.2995 - val_loss: 1.3883 - val_mae: 1.5617\n",
      "Epoch 46/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1616 - mae: 1.3195 - val_loss: 1.3700 - val_mae: 1.5479\n",
      "Epoch 47/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1020 - mae: 1.2620 - val_loss: 1.3726 - val_mae: 1.5529\n",
      "Epoch 48/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1998 - mae: 1.3695 - val_loss: 1.3900 - val_mae: 1.5696\n",
      "Epoch 49/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1378 - mae: 1.3016 - val_loss: 1.3584 - val_mae: 1.5458\n",
      "Epoch 50/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1080 - mae: 1.2807 - val_loss: 1.3636 - val_mae: 1.5527\n",
      "Epoch 51/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1091 - mae: 1.2746 - val_loss: 1.3577 - val_mae: 1.5473\n",
      "Epoch 52/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0714 - mae: 1.2411 - val_loss: 1.3570 - val_mae: 1.5524\n",
      "Epoch 53/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1214 - mae: 1.2988 - val_loss: 1.3468 - val_mae: 1.5403\n",
      "Epoch 54/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1060 - mae: 1.2842 - val_loss: 1.3492 - val_mae: 1.5485\n",
      "Epoch 55/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1449 - mae: 1.3273 - val_loss: 1.3440 - val_mae: 1.5447\n",
      "Epoch 56/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1053 - mae: 1.2855 - val_loss: 1.3517 - val_mae: 1.5524\n",
      "Epoch 57/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1120 - mae: 1.2951 - val_loss: 1.3368 - val_mae: 1.5432\n",
      "Epoch 58/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1805 - mae: 1.3759 - val_loss: 1.3260 - val_mae: 1.5321\n",
      "Epoch 59/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1656 - mae: 1.3607 - val_loss: 1.3368 - val_mae: 1.5464\n",
      "Epoch 60/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0930 - mae: 1.2838 - val_loss: 1.3537 - val_mae: 1.5609\n",
      "Epoch 61/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1781 - mae: 1.3710 - val_loss: 1.3286 - val_mae: 1.5401\n",
      "Epoch 62/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0907 - mae: 1.2876 - val_loss: 1.3331 - val_mae: 1.5493\n",
      "Epoch 63/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1539 - mae: 1.3518 - val_loss: 1.3314 - val_mae: 1.5495\n",
      "Epoch 64/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1453 - mae: 1.3456 - val_loss: 1.3295 - val_mae: 1.5462\n",
      "Epoch 65/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0958 - mae: 1.2981 - val_loss: 1.3379 - val_mae: 1.5542\n",
      "Epoch 66/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0639 - mae: 1.2598 - val_loss: 1.3221 - val_mae: 1.5444\n",
      "Epoch 67/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1787 - mae: 1.3879 - val_loss: 1.3157 - val_mae: 1.5403\n",
      "Epoch 68/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9968 - mae: 1.1980 - val_loss: 1.3293 - val_mae: 1.5529\n",
      "Epoch 69/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0932 - mae: 1.3071 - val_loss: 1.3224 - val_mae: 1.5492\n",
      "Epoch 70/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1154 - mae: 1.3255 - val_loss: 1.3221 - val_mae: 1.5484\n",
      "Epoch 71/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0537 - mae: 1.2586 - val_loss: 1.3130 - val_mae: 1.5434\n",
      "Epoch 72/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1181 - mae: 1.3321 - val_loss: 1.3078 - val_mae: 1.5399\n",
      "Epoch 73/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0713 - mae: 1.2856 - val_loss: 1.3122 - val_mae: 1.5434\n",
      "Epoch 74/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0400 - mae: 1.2536 - val_loss: 1.3107 - val_mae: 1.5435\n",
      "Epoch 75/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0902 - mae: 1.3052 - val_loss: 1.3059 - val_mae: 1.5413\n",
      "Epoch 76/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1079 - mae: 1.3264 - val_loss: 1.3089 - val_mae: 1.5444\n",
      "Epoch 77/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0727 - mae: 1.2820 - val_loss: 1.3038 - val_mae: 1.5413\n",
      "Epoch 78/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0697 - mae: 1.2927 - val_loss: 1.3084 - val_mae: 1.5426\n",
      "Epoch 79/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0614 - mae: 1.2834 - val_loss: 1.3038 - val_mae: 1.5428\n",
      "Epoch 80/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0071 - mae: 1.2237 - val_loss: 1.3029 - val_mae: 1.5464\n",
      "Epoch 81/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0914 - mae: 1.3192 - val_loss: 1.3120 - val_mae: 1.5505\n",
      "Epoch 82/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0817 - mae: 1.3111 - val_loss: 1.3005 - val_mae: 1.5444\n",
      "Epoch 83/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0482 - mae: 1.2676 - val_loss: 1.3013 - val_mae: 1.5448\n",
      "Epoch 84/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0799 - mae: 1.3071 - val_loss: 1.2885 - val_mae: 1.5318\n",
      "Epoch 85/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1418 - mae: 1.3768 - val_loss: 1.3036 - val_mae: 1.5505\n",
      "Epoch 86/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0516 - mae: 1.2816 - val_loss: 1.2880 - val_mae: 1.5377\n",
      "Epoch 87/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0433 - mae: 1.2717 - val_loss: 1.2864 - val_mae: 1.5358\n",
      "Epoch 88/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0796 - mae: 1.3134 - val_loss: 1.2948 - val_mae: 1.5475\n",
      "Epoch 89/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0252 - mae: 1.2591 - val_loss: 1.2963 - val_mae: 1.5438\n",
      "Epoch 90/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0325 - mae: 1.2642 - val_loss: 1.2873 - val_mae: 1.5421\n",
      "Epoch 91/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0693 - mae: 1.3004 - val_loss: 1.2815 - val_mae: 1.5357\n",
      "Epoch 92/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0005 - mae: 1.2317 - val_loss: 1.2959 - val_mae: 1.5463\n",
      "Epoch 93/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0990 - mae: 1.3430 - val_loss: 1.2832 - val_mae: 1.5381\n",
      "Epoch 94/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0410 - mae: 1.2750 - val_loss: 1.2953 - val_mae: 1.5528\n",
      "Epoch 95/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0818 - mae: 1.3185 - val_loss: 1.2857 - val_mae: 1.5423\n",
      "Epoch 96/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0262 - mae: 1.2688 - val_loss: 1.2772 - val_mae: 1.5361\n",
      "Epoch 97/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0247 - mae: 1.2664 - val_loss: 1.2752 - val_mae: 1.5337\n",
      "Epoch 98/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0347 - mae: 1.2812 - val_loss: 1.2827 - val_mae: 1.5440\n",
      "Epoch 99/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0163 - mae: 1.2614 - val_loss: 1.2858 - val_mae: 1.5423\n",
      "Epoch 100/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0638 - mae: 1.3060 - val_loss: 1.2801 - val_mae: 1.5396\n",
      "Epoch 101/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0269 - mae: 1.2633 - val_loss: 1.2808 - val_mae: 1.5451\n",
      "Epoch 102/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0534 - mae: 1.2946 - val_loss: 1.3040 - val_mae: 1.5632\n",
      "Epoch 103/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0777 - mae: 1.3220 - val_loss: 1.2799 - val_mae: 1.5387\n",
      "Epoch 104/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0722 - mae: 1.3183 - val_loss: 1.2763 - val_mae: 1.5416\n",
      "Epoch 105/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0379 - mae: 1.2771 - val_loss: 1.2702 - val_mae: 1.5331\n",
      "Epoch 106/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9939 - mae: 1.2376 - val_loss: 1.2667 - val_mae: 1.5307\n",
      "Epoch 107/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1072 - mae: 1.3602 - val_loss: 1.2850 - val_mae: 1.5496\n",
      "Epoch 108/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0621 - mae: 1.3152 - val_loss: 1.2670 - val_mae: 1.5354\n",
      "Epoch 109/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0581 - mae: 1.3094 - val_loss: 1.2984 - val_mae: 1.5610\n",
      "Epoch 110/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0416 - mae: 1.2905 - val_loss: 1.2800 - val_mae: 1.5469\n",
      "Epoch 111/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0680 - mae: 1.3205 - val_loss: 1.2960 - val_mae: 1.5605\n",
      "Epoch 112/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0976 - mae: 1.3477 - val_loss: 1.2587 - val_mae: 1.5233\n",
      "Epoch 113/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0209 - mae: 1.2717 - val_loss: 1.2797 - val_mae: 1.5511\n",
      "Epoch 114/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0909 - mae: 1.3510 - val_loss: 1.2700 - val_mae: 1.5379\n",
      "Epoch 115/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0471 - mae: 1.3078 - val_loss: 1.2619 - val_mae: 1.5299\n",
      "Epoch 116/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0396 - mae: 1.2941 - val_loss: 1.2812 - val_mae: 1.5502\n",
      "Epoch 117/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0263 - mae: 1.2802 - val_loss: 1.2607 - val_mae: 1.5323\n",
      "Epoch 118/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0436 - mae: 1.3029 - val_loss: 1.2791 - val_mae: 1.5513\n",
      "Epoch 119/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0516 - mae: 1.3041 - val_loss: 1.2680 - val_mae: 1.5388\n",
      "Epoch 120/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0148 - mae: 1.2725 - val_loss: 1.2680 - val_mae: 1.5416\n",
      "Epoch 121/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0174 - mae: 1.2765 - val_loss: 1.2749 - val_mae: 1.5481\n",
      "Epoch 122/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9926 - mae: 1.2494 - val_loss: 1.2489 - val_mae: 1.5187\n",
      "Epoch 123/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0273 - mae: 1.2850 - val_loss: 1.2813 - val_mae: 1.5542\n",
      "Epoch 124/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0210 - mae: 1.2826 - val_loss: 1.2559 - val_mae: 1.5266\n",
      "Epoch 125/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0108 - mae: 1.2675 - val_loss: 1.2794 - val_mae: 1.5546\n",
      "Epoch 126/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0382 - mae: 1.3016 - val_loss: 1.2618 - val_mae: 1.5374\n",
      "Epoch 127/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0054 - mae: 1.2609 - val_loss: 1.2638 - val_mae: 1.5402\n",
      "Epoch 128/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0598 - mae: 1.3279 - val_loss: 1.2687 - val_mae: 1.5466\n",
      "Epoch 129/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0521 - mae: 1.3150 - val_loss: 1.2563 - val_mae: 1.5319\n",
      "Epoch 130/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0058 - mae: 1.2678 - val_loss: 1.2635 - val_mae: 1.5424\n",
      "Epoch 131/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0482 - mae: 1.3212 - val_loss: 1.2792 - val_mae: 1.5563\n",
      "Epoch 132/300\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0668 - mae: 1.3251 - val_loss: 1.2542 - val_mae: 1.5322\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2471 - mae: 1.5200\n",
      "Test MAE: 1.5187489986419678\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Predicted: [3.947506   1.8200419  0.82287234] | Actual: [10.01923077  5.57692308  3.36538462]\n",
      "Predicted: [4.479329  1.7293842 0.9688501] | Actual: [8.86885246 1.63934426 1.        ]\n",
      "Predicted: [5.75431    3.3698604  0.90584487] | Actual: [3.76923077 1.71153846 0.42307692]\n",
      "Predicted: [20.520216   4.865029   2.4287004] | Actual: [27.          7.2295082   3.70491803]\n",
      "Predicted: [5.562508  1.744189  1.0738459] | Actual: [12.07317073  3.7804878   2.06097561]\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=300,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# evaluate model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test MAE: {mae}\")\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# examples\n",
    "for i in range(5):\n",
    "    print(f\"Predicted: {predictions[i]} | Actual: {y_test.iloc[i].values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d722bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "We are 90% confident that the stats will be within these ranges:\n",
      "Points: ±5.67\n",
      "Rebounds: ±2.36\n",
      "Assists: ±1.59\n"
     ]
    }
   ],
   "source": [
    "# Analyze results\n",
    "from scipy import stats\n",
    "\n",
    "# predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate error in predictions\n",
    "errors = y_test.values - y_pred\n",
    "\n",
    "# evaluate std dev of error for confidence\n",
    "std_dev = np.std(errors, axis=0)\n",
    "\n",
    "# compute confidence interval\n",
    "conf_interval = 1.645 * std_dev # 90% confidence\n",
    "\n",
    "print(\"We are 90% confident that the stats will be within these ranges:\")\n",
    "print(f\"Points: ±{conf_interval[0]:.2f}\")\n",
    "print(f\"Rebounds: ±{conf_interval[1]:.2f}\")\n",
    "print(f\"Assists: ±{conf_interval[2]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae82a9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save model to use for predictions\n",
    "model.save(\"stat_prediction_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
