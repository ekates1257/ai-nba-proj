{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ad24407",
   "metadata": {},
   "source": [
    "ANN Final Project\n",
    "Authors: Caleb Johnson, Gabe Schwartz, Evan Kates\n",
    "Network Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09002cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calebjohnson/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/calebjohnson/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# import data from csv file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, losses, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load csv data\n",
    "df = pd.read_csv('training.csv')\n",
    "\n",
    "# define input features\n",
    "feature_cols = ['GP_r', 'MIN_r', 'FG_PCT_r', 'REB_r', 'AST_r', 'PTS_r', 'TOV_r']\n",
    "\n",
    "X = df[feature_cols]\n",
    "\n",
    "# define predicted features\n",
    "target_cols = ['PTS_s', 'REB_s', 'AST_s']\n",
    "y = df[target_cols]\n",
    "\n",
    "# create train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# create model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],),\n",
    "                       kernel_regularizer=regularizers.l1(0.001)),  # L1 regularization\n",
    "    keras.layers.Dense(64, activation='relu',\n",
    "                       kernel_regularizer=regularizers.l1(0.001)),\n",
    "    keras.layers.Dense(3)  # output layer predicts 3 stats\n",
    "])\n",
    "\n",
    "# stop early to avoid overfitting\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True # After stopping, roll back to the best model\n",
    ")\n",
    "\n",
    "model.compile(optimizer='adam', loss=losses.Huber(), metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606e707a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4.9791 - mae: 4.6399 - val_loss: 4.6100 - val_mae: 4.2774\n",
      "Epoch 2/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.3319 - mae: 4.0023 - val_loss: 3.9805 - val_mae: 3.6595\n",
      "Epoch 3/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.5739 - mae: 3.2532 - val_loss: 3.4077 - val_mae: 3.0999\n",
      "Epoch 4/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0551 - mae: 2.7530 - val_loss: 2.9149 - val_mae: 2.6270\n",
      "Epoch 5/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.6946 - mae: 2.4055 - val_loss: 2.4753 - val_mae: 2.2036\n",
      "Epoch 6/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2588 - mae: 1.9869 - val_loss: 2.1518 - val_mae: 1.8916\n",
      "Epoch 7/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9393 - mae: 1.6829 - val_loss: 1.9884 - val_mae: 1.7546\n",
      "Epoch 8/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8793 - mae: 1.6531 - val_loss: 1.8809 - val_mae: 1.6751\n",
      "Epoch 9/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8251 - mae: 1.6293 - val_loss: 1.8269 - val_mae: 1.6492\n",
      "Epoch 10/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.7225 - mae: 1.5468 - val_loss: 1.7747 - val_mae: 1.6220\n",
      "Epoch 11/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6947 - mae: 1.5439 - val_loss: 1.7173 - val_mae: 1.5867\n",
      "Epoch 12/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6649 - mae: 1.5319 - val_loss: 1.6820 - val_mae: 1.5703\n",
      "Epoch 13/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5700 - mae: 1.4560 - val_loss: 1.6440 - val_mae: 1.5506\n",
      "Epoch 14/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5794 - mae: 1.4854 - val_loss: 1.6060 - val_mae: 1.5202\n",
      "Epoch 15/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6131 - mae: 1.5377 - val_loss: 1.5755 - val_mae: 1.5093\n",
      "Epoch 16/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5101 - mae: 1.4404 - val_loss: 1.5456 - val_mae: 1.4896\n",
      "Epoch 17/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5201 - mae: 1.4683 - val_loss: 1.5157 - val_mae: 1.4711\n",
      "Epoch 18/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3706 - mae: 1.3183 - val_loss: 1.5049 - val_mae: 1.4774\n",
      "Epoch 19/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4642 - mae: 1.4386 - val_loss: 1.4888 - val_mae: 1.4676\n",
      "Epoch 20/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4714 - mae: 1.4511 - val_loss: 1.4678 - val_mae: 1.4546\n",
      "Epoch 21/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4079 - mae: 1.3915 - val_loss: 1.4504 - val_mae: 1.4484\n",
      "Epoch 22/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4086 - mae: 1.4085 - val_loss: 1.4199 - val_mae: 1.4314\n",
      "Epoch 23/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4426 - mae: 1.4467 - val_loss: 1.4182 - val_mae: 1.4370\n",
      "Epoch 24/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4290 - mae: 1.4486 - val_loss: 1.3963 - val_mae: 1.4262\n",
      "Epoch 25/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3522 - mae: 1.3728 - val_loss: 1.3906 - val_mae: 1.4214\n",
      "Epoch 26/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3600 - mae: 1.3909 - val_loss: 1.3762 - val_mae: 1.4225\n",
      "Epoch 27/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3845 - mae: 1.4278 - val_loss: 1.3698 - val_mae: 1.4161\n",
      "Epoch 28/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2764 - mae: 1.3188 - val_loss: 1.3465 - val_mae: 1.4042\n",
      "Epoch 29/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3539 - mae: 1.4066 - val_loss: 1.3463 - val_mae: 1.4098\n",
      "Epoch 30/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3463 - mae: 1.4109 - val_loss: 1.3353 - val_mae: 1.4053\n",
      "Epoch 31/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2925 - mae: 1.3548 - val_loss: 1.3275 - val_mae: 1.4044\n",
      "Epoch 32/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3291 - mae: 1.4051 - val_loss: 1.3184 - val_mae: 1.4010\n",
      "Epoch 33/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3381 - mae: 1.4173 - val_loss: 1.3098 - val_mae: 1.3996\n",
      "Epoch 34/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2349 - mae: 1.3187 - val_loss: 1.3060 - val_mae: 1.3986\n",
      "Epoch 35/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3006 - mae: 1.3978 - val_loss: 1.3108 - val_mae: 1.4098\n",
      "Epoch 36/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2188 - mae: 1.3096 - val_loss: 1.2895 - val_mae: 1.3966\n",
      "Epoch 37/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2639 - mae: 1.3619 - val_loss: 1.2835 - val_mae: 1.3949\n",
      "Epoch 38/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2412 - mae: 1.3460 - val_loss: 1.2780 - val_mae: 1.3875\n",
      "Epoch 39/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2940 - mae: 1.4026 - val_loss: 1.2770 - val_mae: 1.3912\n",
      "Epoch 40/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2519 - mae: 1.3583 - val_loss: 1.2616 - val_mae: 1.3844\n",
      "Epoch 41/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2676 - mae: 1.3814 - val_loss: 1.2615 - val_mae: 1.3860\n",
      "Epoch 42/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2378 - mae: 1.3511 - val_loss: 1.2549 - val_mae: 1.3864\n",
      "Epoch 43/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1604 - mae: 1.2852 - val_loss: 1.2595 - val_mae: 1.3884\n",
      "Epoch 44/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2266 - mae: 1.3517 - val_loss: 1.2444 - val_mae: 1.3811\n",
      "Epoch 45/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2135 - mae: 1.3432 - val_loss: 1.2418 - val_mae: 1.3843\n",
      "Epoch 46/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2126 - mae: 1.3487 - val_loss: 1.2368 - val_mae: 1.3790\n",
      "Epoch 47/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2307 - mae: 1.3679 - val_loss: 1.2318 - val_mae: 1.3807\n",
      "Epoch 48/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1720 - mae: 1.3151 - val_loss: 1.2305 - val_mae: 1.3788\n",
      "Epoch 49/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1845 - mae: 1.3303 - val_loss: 1.2349 - val_mae: 1.3873\n",
      "Epoch 50/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1856 - mae: 1.3314 - val_loss: 1.2168 - val_mae: 1.3756\n",
      "Epoch 51/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2184 - mae: 1.3732 - val_loss: 1.2207 - val_mae: 1.3803\n",
      "Epoch 52/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2057 - mae: 1.3593 - val_loss: 1.2125 - val_mae: 1.3757\n",
      "Epoch 53/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1951 - mae: 1.3460 - val_loss: 1.2035 - val_mae: 1.3702\n",
      "Epoch 54/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1253 - mae: 1.2818 - val_loss: 1.2096 - val_mae: 1.3795\n",
      "Epoch 55/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1842 - mae: 1.3478 - val_loss: 1.2045 - val_mae: 1.3736\n",
      "Epoch 56/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2018 - mae: 1.3670 - val_loss: 1.1946 - val_mae: 1.3684\n",
      "Epoch 57/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1329 - mae: 1.2944 - val_loss: 1.2054 - val_mae: 1.3785\n",
      "Epoch 58/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1358 - mae: 1.2938 - val_loss: 1.1911 - val_mae: 1.3711\n",
      "Epoch 59/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1866 - mae: 1.3535 - val_loss: 1.1930 - val_mae: 1.3700\n",
      "Epoch 60/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1736 - mae: 1.3439 - val_loss: 1.1901 - val_mae: 1.3737\n",
      "Epoch 61/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1343 - mae: 1.3083 - val_loss: 1.1787 - val_mae: 1.3626\n",
      "Epoch 62/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1000 - mae: 1.2729 - val_loss: 1.1905 - val_mae: 1.3791\n",
      "Epoch 63/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1631 - mae: 1.3442 - val_loss: 1.1760 - val_mae: 1.3630\n",
      "Epoch 64/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1160 - mae: 1.2893 - val_loss: 1.1815 - val_mae: 1.3758\n",
      "Epoch 65/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1297 - mae: 1.3157 - val_loss: 1.1745 - val_mae: 1.3655\n",
      "Epoch 66/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1358 - mae: 1.3164 - val_loss: 1.1708 - val_mae: 1.3671\n",
      "Epoch 67/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1696 - mae: 1.3567 - val_loss: 1.1692 - val_mae: 1.3666\n",
      "Epoch 68/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0840 - mae: 1.2628 - val_loss: 1.1607 - val_mae: 1.3597\n",
      "Epoch 69/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0703 - mae: 1.2574 - val_loss: 1.1740 - val_mae: 1.3732\n",
      "Epoch 70/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1095 - mae: 1.2978 - val_loss: 1.1607 - val_mae: 1.3618\n",
      "Epoch 71/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1535 - mae: 1.3489 - val_loss: 1.1577 - val_mae: 1.3621\n",
      "Epoch 72/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1601 - mae: 1.3553 - val_loss: 1.1588 - val_mae: 1.3660\n",
      "Epoch 73/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1394 - mae: 1.3364 - val_loss: 1.1565 - val_mae: 1.3617\n",
      "Epoch 74/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1113 - mae: 1.3052 - val_loss: 1.1532 - val_mae: 1.3641\n",
      "Epoch 75/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0884 - mae: 1.2850 - val_loss: 1.1539 - val_mae: 1.3640\n",
      "Epoch 76/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1276 - mae: 1.3264 - val_loss: 1.1483 - val_mae: 1.3601\n",
      "Epoch 77/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1358 - mae: 1.3406 - val_loss: 1.1739 - val_mae: 1.3832\n",
      "Epoch 78/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1974 - mae: 1.4069 - val_loss: 1.1444 - val_mae: 1.3555\n",
      "Epoch 79/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1696 - mae: 1.3761 - val_loss: 1.1457 - val_mae: 1.3620\n",
      "Epoch 80/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1148 - mae: 1.3220 - val_loss: 1.1412 - val_mae: 1.3579\n",
      "Epoch 81/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1624 - mae: 1.3720 - val_loss: 1.1470 - val_mae: 1.3686\n",
      "Epoch 82/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1320 - mae: 1.3429 - val_loss: 1.1405 - val_mae: 1.3542\n",
      "Epoch 83/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1013 - mae: 1.3061 - val_loss: 1.1410 - val_mae: 1.3661\n",
      "Epoch 84/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0898 - mae: 1.2993 - val_loss: 1.1374 - val_mae: 1.3569\n",
      "Epoch 85/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1504 - mae: 1.3613 - val_loss: 1.1401 - val_mae: 1.3607\n",
      "Epoch 86/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1310 - mae: 1.3437 - val_loss: 1.1343 - val_mae: 1.3604\n",
      "Epoch 87/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1134 - mae: 1.3246 - val_loss: 1.1284 - val_mae: 1.3504\n",
      "Epoch 88/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1626 - mae: 1.3828 - val_loss: 1.1478 - val_mae: 1.3746\n",
      "Epoch 89/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1306 - mae: 1.3479 - val_loss: 1.1279 - val_mae: 1.3548\n",
      "Epoch 90/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1139 - mae: 1.3327 - val_loss: 1.1285 - val_mae: 1.3622\n",
      "Epoch 91/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1239 - mae: 1.3493 - val_loss: 1.1290 - val_mae: 1.3585\n",
      "Epoch 92/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1292 - mae: 1.3452 - val_loss: 1.1251 - val_mae: 1.3569\n",
      "Epoch 93/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1806 - mae: 1.4077 - val_loss: 1.1303 - val_mae: 1.3634\n",
      "Epoch 94/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1760 - mae: 1.4004 - val_loss: 1.1220 - val_mae: 1.3531\n",
      "Epoch 95/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1520 - mae: 1.3762 - val_loss: 1.1231 - val_mae: 1.3557\n",
      "Epoch 96/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1230 - mae: 1.3447 - val_loss: 1.1246 - val_mae: 1.3600\n",
      "Epoch 97/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1477 - mae: 1.3678 - val_loss: 1.1228 - val_mae: 1.3602\n",
      "Epoch 98/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0918 - mae: 1.3168 - val_loss: 1.1284 - val_mae: 1.3594\n",
      "Epoch 99/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1581 - mae: 1.3869 - val_loss: 1.1245 - val_mae: 1.3635\n",
      "Epoch 100/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1091 - mae: 1.3283 - val_loss: 1.1162 - val_mae: 1.3523\n",
      "Epoch 101/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1489 - mae: 1.3783 - val_loss: 1.1277 - val_mae: 1.3656\n",
      "Epoch 102/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1545 - mae: 1.3859 - val_loss: 1.1149 - val_mae: 1.3529\n",
      "Epoch 103/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0977 - mae: 1.3309 - val_loss: 1.1184 - val_mae: 1.3568\n",
      "Epoch 104/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1027 - mae: 1.3315 - val_loss: 1.1146 - val_mae: 1.3533\n",
      "Epoch 105/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0645 - mae: 1.2881 - val_loss: 1.1111 - val_mae: 1.3527\n",
      "Epoch 106/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1297 - mae: 1.3674 - val_loss: 1.1325 - val_mae: 1.3750\n",
      "Epoch 107/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1293 - mae: 1.3627 - val_loss: 1.1106 - val_mae: 1.3547\n",
      "Epoch 108/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1708 - mae: 1.4099 - val_loss: 1.1129 - val_mae: 1.3574\n",
      "Epoch 109/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0569 - mae: 1.2866 - val_loss: 1.1131 - val_mae: 1.3551\n",
      "Epoch 110/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0439 - mae: 1.2659 - val_loss: 1.1099 - val_mae: 1.3565\n",
      "Epoch 111/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1069 - mae: 1.3477 - val_loss: 1.1105 - val_mae: 1.3534\n",
      "Epoch 112/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1126 - mae: 1.3449 - val_loss: 1.1063 - val_mae: 1.3546\n",
      "Epoch 113/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1571 - mae: 1.3968 - val_loss: 1.1039 - val_mae: 1.3488\n",
      "Epoch 114/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0432 - mae: 1.2695 - val_loss: 1.1119 - val_mae: 1.3628\n",
      "Epoch 115/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0367 - mae: 1.2755 - val_loss: 1.1078 - val_mae: 1.3543\n",
      "Epoch 116/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1187 - mae: 1.3534 - val_loss: 1.1086 - val_mae: 1.3594\n",
      "Epoch 117/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0679 - mae: 1.3011 - val_loss: 1.1224 - val_mae: 1.3675\n",
      "Epoch 118/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0760 - mae: 1.3149 - val_loss: 1.1028 - val_mae: 1.3531\n",
      "Epoch 119/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1325 - mae: 1.3751 - val_loss: 1.1187 - val_mae: 1.3702\n",
      "Epoch 120/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0668 - mae: 1.3034 - val_loss: 1.0995 - val_mae: 1.3522\n",
      "Epoch 121/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0289 - mae: 1.2691 - val_loss: 1.1007 - val_mae: 1.3551\n",
      "Epoch 122/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0836 - mae: 1.3282 - val_loss: 1.1016 - val_mae: 1.3535\n",
      "Epoch 123/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1427 - mae: 1.3907 - val_loss: 1.0967 - val_mae: 1.3509\n",
      "Epoch 124/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0439 - mae: 1.2792 - val_loss: 1.0987 - val_mae: 1.3556\n",
      "Epoch 125/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0510 - mae: 1.2950 - val_loss: 1.1042 - val_mae: 1.3597\n",
      "Epoch 126/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0564 - mae: 1.2951 - val_loss: 1.0942 - val_mae: 1.3522\n",
      "Epoch 127/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0875 - mae: 1.3351 - val_loss: 1.0952 - val_mae: 1.3498\n",
      "Epoch 128/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1406 - mae: 1.3890 - val_loss: 1.0921 - val_mae: 1.3489\n",
      "Epoch 129/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0983 - mae: 1.3419 - val_loss: 1.0942 - val_mae: 1.3527\n",
      "Epoch 130/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1426 - mae: 1.3948 - val_loss: 1.0943 - val_mae: 1.3532\n",
      "Epoch 131/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1243 - mae: 1.3793 - val_loss: 1.0919 - val_mae: 1.3522\n",
      "Epoch 132/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0960 - mae: 1.3431 - val_loss: 1.1017 - val_mae: 1.3612\n",
      "Epoch 133/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1084 - mae: 1.3564 - val_loss: 1.0932 - val_mae: 1.3536\n",
      "Epoch 134/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0983 - mae: 1.3533 - val_loss: 1.0893 - val_mae: 1.3486\n",
      "Epoch 135/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0167 - mae: 1.2673 - val_loss: 1.0974 - val_mae: 1.3552\n",
      "Epoch 136/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0793 - mae: 1.3278 - val_loss: 1.0911 - val_mae: 1.3551\n",
      "Epoch 137/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0363 - mae: 1.2852 - val_loss: 1.0878 - val_mae: 1.3474\n",
      "Epoch 138/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0674 - mae: 1.3230 - val_loss: 1.0911 - val_mae: 1.3555\n",
      "Epoch 139/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0725 - mae: 1.3247 - val_loss: 1.0909 - val_mae: 1.3525\n",
      "Epoch 140/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0653 - mae: 1.3096 - val_loss: 1.0874 - val_mae: 1.3521\n",
      "Epoch 141/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0941 - mae: 1.3520 - val_loss: 1.0900 - val_mae: 1.3549\n",
      "Epoch 142/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0552 - mae: 1.3111 - val_loss: 1.0841 - val_mae: 1.3503\n",
      "Epoch 143/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0935 - mae: 1.3497 - val_loss: 1.0804 - val_mae: 1.3451\n",
      "Epoch 144/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0961 - mae: 1.3502 - val_loss: 1.0890 - val_mae: 1.3554\n",
      "Epoch 145/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0490 - mae: 1.2994 - val_loss: 1.0806 - val_mae: 1.3459\n",
      "Epoch 146/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1081 - mae: 1.3635 - val_loss: 1.0830 - val_mae: 1.3496\n",
      "Epoch 147/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1453 - mae: 1.4030 - val_loss: 1.0895 - val_mae: 1.3549\n",
      "Epoch 148/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0960 - mae: 1.3527 - val_loss: 1.0773 - val_mae: 1.3454\n",
      "Epoch 149/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0469 - mae: 1.3058 - val_loss: 1.0859 - val_mae: 1.3539\n",
      "Epoch 150/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9978 - mae: 1.2457 - val_loss: 1.0823 - val_mae: 1.3518\n",
      "Epoch 151/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0221 - mae: 1.2789 - val_loss: 1.0852 - val_mae: 1.3517\n",
      "Epoch 152/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0490 - mae: 1.3044 - val_loss: 1.0901 - val_mae: 1.3613\n",
      "Epoch 153/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0973 - mae: 1.3617 - val_loss: 1.0802 - val_mae: 1.3500\n",
      "Epoch 154/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.0819 - mae: 1.3435 - val_loss: 1.0753 - val_mae: 1.3475\n",
      "Epoch 155/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1019 - mae: 1.3722 - val_loss: 1.0775 - val_mae: 1.3492\n",
      "Epoch 156/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0785 - mae: 1.3426 - val_loss: 1.0798 - val_mae: 1.3504\n",
      "Epoch 157/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0083 - mae: 1.2649 - val_loss: 1.0766 - val_mae: 1.3475\n",
      "Epoch 158/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0470 - mae: 1.3035 - val_loss: 1.0796 - val_mae: 1.3532\n",
      "Epoch 159/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0831 - mae: 1.3459 - val_loss: 1.0844 - val_mae: 1.3532\n",
      "Epoch 160/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0435 - mae: 1.3012 - val_loss: 1.0727 - val_mae: 1.3486\n",
      "Epoch 161/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0375 - mae: 1.3025 - val_loss: 1.1024 - val_mae: 1.3750\n",
      "Epoch 162/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0820 - mae: 1.3443 - val_loss: 1.0753 - val_mae: 1.3493\n",
      "Epoch 163/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0677 - mae: 1.3304 - val_loss: 1.0802 - val_mae: 1.3527\n",
      "Epoch 164/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0516 - mae: 1.3187 - val_loss: 1.0723 - val_mae: 1.3481\n",
      "Epoch 165/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0842 - mae: 1.3524 - val_loss: 1.0840 - val_mae: 1.3581\n",
      "Epoch 166/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0243 - mae: 1.2803 - val_loss: 1.0727 - val_mae: 1.3481\n",
      "Epoch 167/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1047 - mae: 1.3694 - val_loss: 1.0865 - val_mae: 1.3610\n",
      "Epoch 168/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0206 - mae: 1.2798 - val_loss: 1.0699 - val_mae: 1.3451\n",
      "Epoch 169/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0464 - mae: 1.3135 - val_loss: 1.0696 - val_mae: 1.3460\n",
      "Epoch 170/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0168 - mae: 1.2788 - val_loss: 1.0709 - val_mae: 1.3486\n",
      "Epoch 171/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0945 - mae: 1.3632 - val_loss: 1.0797 - val_mae: 1.3562\n",
      "Epoch 172/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0364 - mae: 1.3008 - val_loss: 1.0691 - val_mae: 1.3465\n",
      "Epoch 173/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1094 - mae: 1.3764 - val_loss: 1.0708 - val_mae: 1.3485\n",
      "Epoch 174/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0681 - mae: 1.3358 - val_loss: 1.0744 - val_mae: 1.3515\n",
      "Epoch 175/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0668 - mae: 1.3324 - val_loss: 1.0680 - val_mae: 1.3467\n",
      "Epoch 176/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0969 - mae: 1.3666 - val_loss: 1.0718 - val_mae: 1.3503\n",
      "Epoch 177/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9909 - mae: 1.2504 - val_loss: 1.0675 - val_mae: 1.3463\n",
      "Epoch 178/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0838 - mae: 1.3494 - val_loss: 1.0701 - val_mae: 1.3505\n",
      "Epoch 179/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0899 - mae: 1.3579 - val_loss: 1.0640 - val_mae: 1.3436\n",
      "Epoch 180/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0387 - mae: 1.3056 - val_loss: 1.0642 - val_mae: 1.3430\n",
      "Epoch 181/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0398 - mae: 1.3092 - val_loss: 1.0653 - val_mae: 1.3467\n",
      "Epoch 182/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0791 - mae: 1.3545 - val_loss: 1.0781 - val_mae: 1.3575\n",
      "Epoch 183/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0937 - mae: 1.3680 - val_loss: 1.0650 - val_mae: 1.3456\n",
      "Epoch 184/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0124 - mae: 1.2716 - val_loss: 1.0703 - val_mae: 1.3519\n",
      "Epoch 185/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0296 - mae: 1.2994 - val_loss: 1.0814 - val_mae: 1.3609\n",
      "Epoch 186/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0810 - mae: 1.3490 - val_loss: 1.0667 - val_mae: 1.3492\n",
      "Epoch 187/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0462 - mae: 1.3200 - val_loss: 1.0689 - val_mae: 1.3479\n",
      "Epoch 188/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.9673 - mae: 1.2430 - val_loss: 1.0700 - val_mae: 1.3505\n",
      "Epoch 189/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0821 - mae: 1.3563 - val_loss: 1.0629 - val_mae: 1.3440\n",
      "Epoch 190/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0507 - mae: 1.3302 - val_loss: 1.0648 - val_mae: 1.3479\n",
      "Epoch 191/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0667 - mae: 1.3414 - val_loss: 1.0741 - val_mae: 1.3562\n",
      "Epoch 192/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0440 - mae: 1.3161 - val_loss: 1.0625 - val_mae: 1.3454\n",
      "Epoch 193/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0678 - mae: 1.3442 - val_loss: 1.0730 - val_mae: 1.3546\n",
      "Epoch 194/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0843 - mae: 1.3578 - val_loss: 1.0592 - val_mae: 1.3438\n",
      "Epoch 195/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0335 - mae: 1.3054 - val_loss: 1.0620 - val_mae: 1.3471\n",
      "Epoch 196/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1320 - mae: 1.4138 - val_loss: 1.0643 - val_mae: 1.3493\n",
      "Epoch 197/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0013 - mae: 1.2709 - val_loss: 1.0603 - val_mae: 1.3477\n",
      "Epoch 198/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1120 - mae: 1.3898 - val_loss: 1.0779 - val_mae: 1.3618\n",
      "Epoch 199/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0473 - mae: 1.3201 - val_loss: 1.0566 - val_mae: 1.3404\n",
      "Epoch 200/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0550 - mae: 1.3329 - val_loss: 1.0591 - val_mae: 1.3441\n",
      "Epoch 201/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0478 - mae: 1.3250 - val_loss: 1.0875 - val_mae: 1.3679\n",
      "Epoch 202/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0919 - mae: 1.3714 - val_loss: 1.0603 - val_mae: 1.3449\n",
      "Epoch 203/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0208 - mae: 1.3002 - val_loss: 1.0589 - val_mae: 1.3444\n",
      "Epoch 204/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0680 - mae: 1.3486 - val_loss: 1.0709 - val_mae: 1.3555\n",
      "Epoch 205/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0735 - mae: 1.3522 - val_loss: 1.0629 - val_mae: 1.3518\n",
      "Epoch 206/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0599 - mae: 1.3407 - val_loss: 1.0722 - val_mae: 1.3557\n",
      "Epoch 207/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0613 - mae: 1.3328 - val_loss: 1.0587 - val_mae: 1.3446\n",
      "Epoch 208/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0339 - mae: 1.3143 - val_loss: 1.0649 - val_mae: 1.3529\n",
      "Epoch 209/300\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0361 - mae: 1.3134 - val_loss: 1.0570 - val_mae: 1.3455\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1058 - mae: 1.3951\n",
      "Test MAE: 1.3403680324554443\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "Predicted: [3.6744785 2.3245213 0.7831774] | Actual: [8.60465116 8.90697674 0.23255814]\n",
      "Predicted: [4.7784247  2.4178708  0.88302076] | Actual: [4.23880597 2.11940299 0.89552239]\n",
      "Predicted: [3.9653723 2.3030598 0.8199513] | Actual: [2.67647059 1.11764706 1.82352941]\n",
      "Predicted: [9.006015  3.5984423 1.4366277] | Actual: [6.84285714 3.         1.14285714]\n",
      "Predicted: [6.459585   5.33374    0.96924424] | Actual: [13.09090909 11.90909091  1.85714286]\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=300,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# evaluate model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test MAE: {mae}\")\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# examples\n",
    "for i in range(5):\n",
    "    print(f\"Predicted: {predictions[i]} | Actual: {y_test.iloc[i].values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d722bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "We are 90% confident that the stats will be within these ranges:\n",
      "Points: ±4.57\n",
      "Rebounds: ±2.67\n",
      "Assists: ±1.26\n"
     ]
    }
   ],
   "source": [
    "# Analyze results\n",
    "from scipy import stats\n",
    "\n",
    "# predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate error in predictions\n",
    "errors = y_test.values - y_pred\n",
    "\n",
    "# evaluate std dev of error for confidence\n",
    "std_dev = np.std(errors, axis=0)\n",
    "\n",
    "# compute confidence interval\n",
    "conf_interval = 1.645 * std_dev # 90% confidence\n",
    "\n",
    "print(\"We are 90% confident that the stats will be within these ranges:\")\n",
    "print(f\"Points: ±{conf_interval[0]:.2f}\")\n",
    "print(f\"Rebounds: ±{conf_interval[1]:.2f}\")\n",
    "print(f\"Assists: ±{conf_interval[2]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae82a9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save model to use for predictions\n",
    "model.save(\"stat_prediction_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
